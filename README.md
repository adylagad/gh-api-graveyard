# gh-api-graveyard

[![Tests](https://github.com/adylagad/gh-api-graveyard/workflows/Tests%20and%20Code%20Quality/badge.svg)](https://github.com/adylagad/gh-api-graveyard/actions)
[![codecov](https://codecov.io/gh/adylagad/gh-api-graveyard/branch/main/graph/badge.svg)](https://codecov.io/gh/adylagad/gh-api-graveyard)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

ðŸª¦ **The simplest way to find and remove unused API endpoints**

A GitHub CLI extension that automatically analyzes your OpenAPI spec, identifies unused endpoints, and creates PRs to remove them.

## ðŸ“¦ Installation

```bash
gh extension install adylagad/gh-api-graveyard
```

## Usage - Super Simple! ðŸš€

Just two commands:

```bash
# 1. Scan and generate report
gh api-graveyard scan

# 2. Create PR to remove unused endpoints
gh api-graveyard prune --dry-run  # Preview first
gh api-graveyard prune            # Create PR
```

**That's it!** No more long command lines with --spec and --logs flags!

## ðŸ”§ How It Works

### Auto-Discovery âœ¨

The tool automatically finds:
- ðŸ“„ **OpenAPI spec**: Searches for `openapi.yaml`, `spec/openapi.yaml`, `api-spec.yaml`, etc.
- ðŸ“‹ **Log files**: Searches for `logs/*.jsonl`, `access.jsonl`, `logs.json`, etc.
- âš™ï¸ **Config**: Reads `.graveyard.yml` if present for custom settings

### âš™ï¸ Optional Config File

Create `.graveyard.yml` in your repo root for custom settings:

```yaml
spec: api/openapi.yaml
logs: data/access.jsonl
service: My API
threshold: 85
```

Now commands are even simpler - everything uses your config!

## ðŸ’» Commands

### `gh api-graveyard scan` ðŸ”

Generate a usage report (auto-discovers spec and logs).

**Basic:**
```bash
gh api-graveyard scan
```

**With options:**
```bash
gh api-graveyard scan --spec api.yaml --logs logs.jsonl --service "My API"
```

### `gh api-graveyard prune` âœ‚ï¸

Remove unused endpoints and create a PR (auto-discovers everything).

**Preview first (recommended):**
```bash
gh api-graveyard prune --dry-run
```

**Create PR:**
```bash
gh api-graveyard prune
```

**With custom threshold:**
```bash
gh api-graveyard prune --threshold 90
```

## ðŸ“š Examples

### Minimal Setup

Just put your files in standard locations and run:

```bash
# Project structure:
# .
# â”œâ”€â”€ openapi.yaml          # â† Auto-discovered
# â””â”€â”€ logs/
#     â””â”€â”€ access.jsonl      # â† Auto-discovered

gh api-graveyard scan    # Works automatically!
gh api-graveyard prune --dry-run
```

### With Config File

```yaml
# .graveyard.yml
spec: spec/api.yaml
logs: data/logs.jsonl
service: Payment API
threshold: 85
```

```bash
gh api-graveyard scan    # Uses all config values
gh api-graveyard prune   # Uses config defaults
```

### Manual Override

Config file present but want to use different files:

```bash
gh api-graveyard scan --spec other-api.yaml --logs other-logs.jsonl
```

## ðŸ§  What Gets Analyzed

The tool:
1. ðŸ” **Finds** all endpoints in your OpenAPI spec
2. ðŸ”— **Matches** log entries to endpoints using path templates
3. ðŸ“ˆ **Calculates** confidence scores based on:
   - Call frequency (fewer calls = higher score)
   - Recency (older = higher score)
   - Caller diversity (fewer callers = higher score)
4. ðŸ“Š **Reports** findings in markdown table
5. âœ‚ï¸ **Removes** high-confidence unused endpoints (prune mode)
6. ðŸ”€ **Creates** PR with detailed analysis

## ðŸ“Š Confidence Scores

- ðŸ’€ **100**: Never called
- ðŸ”´ **80-99**: Very likely unused
- ðŸŸ  **60-79**: Possibly unused  
- ðŸŸ¡ **40-59**: Moderate usage
- ðŸŸ¢ **0-39**: Actively used

Default threshold for removal: **80**

## ðŸ“ Log Format

JSONL format (one JSON object per line):

```jsonl
{"method": "GET", "path": "/users/123", "timestamp": "2026-02-05T10:15:30Z", "caller": "web-app"}
{"method": "POST", "path": "/users", "timestamp": "2026-02-05T11:20:00Z", "caller": "mobile-app"}
```

**Required:** `method`, `path`  
**Optional:** `timestamp`, `caller`/`user`/`client_id` ðŸ‘¤

## âš¡ Advanced Options

All commands support these optional flags:

- `--spec PATH`: Override auto-discovered spec path
- `--logs PATH`: Override auto-discovered logs path
- `--threshold N`: Confidence threshold (default: 80)
- `--window N`: Only analyze logs from last N days
- `--service NAME`: Custom service name for reports
- `--branch NAME`: Custom git branch name
- `--title TEXT`: Custom PR title
- `--base BRANCH`: Base branch for PR (default: main)
- `--dry-run`: Preview without making changes

## ðŸ› ï¸ Development

```bash
git clone https://github.com/adylagad/gh-api-graveyard.git
cd gh-api-graveyard
pip install -e .
gh extension install .
```

## ðŸ“ Project Structure

```
.
â”œâ”€â”€ gh-api-graveyard       # CLI entry point
â”œâ”€â”€ .graveyard.yml        # Optional config
â”œâ”€â”€ detector/
â”‚   â”œâ”€â”€ cli.py           # CLI commands
â”‚   â”œâ”€â”€ parsers.py       # OpenAPI & log parsing
â”‚   â”œâ”€â”€ analysis.py      # Usage analysis logic
â”‚   â”œâ”€â”€ reports.py       # Report generation
â”‚   â”œâ”€â”€ spec_modifier.py # Spec file modification
â”‚   â”œâ”€â”€ git_ops.py       # Git/GitHub operations
â”‚   â””â”€â”€ discovery.py     # Auto-discovery logic
â””â”€â”€ samples/             # Example files
```

## ðŸ› ï¸ Development

### Setup

```bash
git clone https://github.com/adylagad/gh-api-graveyard.git
cd gh-api-graveyard
pip install -e ".[dev]"
gh extension install .
```

### Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=detector --cov-report=html

# Run specific test file
pytest tests/unit/test_parsers.py -v
```

### Code Quality

```bash
# Format code
black detector/ tests/

# Sort imports
isort detector/ tests/ --profile black

# Lint
flake8 detector/ tests/

# Type check
mypy detector/ --ignore-missing-imports

# Run all checks
black detector/ tests/ && isort detector/ tests/ --profile black && flake8 detector/ tests/ && mypy detector/
```

## ðŸ”„ GitHub Actions

Use in CI to auto-scan PRs:

```yaml
- name: Scan for unused endpoints
  run: |
    gh extension install adylagad/gh-api-graveyard
    gh api-graveyard scan
```

## ðŸ¤ Contributing

PRs welcome! Open an issue first for major changes.

## ðŸ“„ License

MIT

## Performance & Scalability

### Memory-Efficient Log Processing

gh-api-graveyard is optimized for enterprise-scale log volumes. The tool uses streaming processing to handle log files of any size without loading them entirely into memory.

**Key Features:**
- **Streaming Architecture**: Processes logs line-by-line using generators
- **Constant Memory Usage**: Memory footprint remains stable regardless of file size
- **Large File Support**: Tested with 50k+ log entries and 100+ endpoints
- **Fast Processing**: ~500k entries/second on modern hardware

**Performance Benchmarks:**
- 10,000 log entries: ~0.02s
- 50,000 log entries: ~1.8s (with 100 endpoints)
- Memory usage: O(1) - constant regardless of file size

### Usage Tips

For optimal performance with large log files:

```bash
# Stream processing is automatic - no special flags needed
gh api-graveyard scan openapi.yaml logs.jsonl --output unused.json

# For very large files (>100MB), the tool will automatically:
# - Stream logs instead of loading into memory
# - Process in a single pass
# - Show progress for long-running operations
```

### Testing

Run the full test suite including performance tests:

```bash
# Run all tests (excluding slow tests)
pytest tests/ -m "not slow"

# Run performance benchmarks
pytest tests/performance/ -v -s

# Run slow tests (multi-million entry benchmarks)
pytest tests/ -m slow -v -s
```

